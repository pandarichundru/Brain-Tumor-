# -*- coding: utf-8 -*-
"""Brain_Tumor 2382005.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zS36y1RHfhoLA31vH6dFXj9OsFAehEeD
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import itertools

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

from sklearn.neural_network import MLPClassifier

# Set the tumor categories
tumors = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']

# Function to display 5 images from each folder side by side
def display_images_from_folders(folder_paths, n=5):
    fig, axs = plt.subplots(len(folder_paths), n, figsize=(8, 3))
    for i, folder_path in enumerate(folder_paths):
        image_files = os.listdir(folder_path)
        for j in range(n):
            image_path = os.path.join(folder_path, image_files[j])
            image = cv2.imread(image_path)
            axs[j].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            axs[j].axis('off')
            axs[j].set_title(f'{os.path.basename(folder_path)}')
    plt.tight_layout()
    plt.show()

def load_images(dir, title):
  folder = dir
  data = []
  labels = []

  # Loop through each tumor category
  for tumor in tumors:
    # Set the path to the tumor category folder
    tumor_folder = os.path.join(folder, tumor)

    # Display 5 images from the folder
    display_images_from_folders([tumor_folder])

    # Get the list of image filenames in the folder
    image_files = os.listdir(tumor_folder)

    # Loop through each image file
    for image_file in image_files:
        # Read the image
        image_path = os.path.join(tumor_folder, image_file)
        image = cv2.imread(image_path)

        # Resize the image to a fixed size (e.g., 48x48 pixels)
        resized_image = cv2.resize(image, (48, 48))

        # Normalize the image data
        normalized_image = resized_image / 255.0

        # Append the image data and label to the lists
        data.append(normalized_image)
        labels.append(tumor)

  # Convert the data and labels lists to NumPy arrays
  data = np.array(data)
  labels = np.array(labels)

  # Display the bar chart showing the number of images in each class
  num_images_per_class = [len(data[labels == tumor]) for tumor in tumors]
  plt.bar(tumors, num_images_per_class)
  plt.xlabel('Tumor')
  plt.ylabel('Number of Images')
  plt.title(f'Images in {title} set')
  plt.show()

  return data, labels

X_train, y_train = load_images('/content/drive/MyDrive/Brain Tumor Classification/Training', 'Training')

X_test, y_test = load_images('/content/drive/MyDrive/Brain Tumor Classification/Testing', 'Testing')

# Getting the percentage of frequency of classes in training and testing sets
f, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))
pd.DataFrame(y_train).value_counts().plot.pie(autopct='%1.1f%%',ax=ax[0])
ax[0].set_title('Training set: Tumor distribution')
pd.DataFrame(y_test).value_counts().plot.pie(autopct='%1.1f%%',ax=ax[1])
ax[1].set_title('Testing set: Tumor distribution')
plt.show()

y_train_new = []
for i in y_train:
    y_train_new.append(tumors.index(i))
y_train_1 = y_train_new
y_train_1 = tf.keras.utils.to_categorical(y_train_1)


y_test_new = []
for i in y_test:
    y_test_new.append(tumors.index(i))
y_test_1 = y_test_new
y_test_1 = tf.keras.utils.to_categorical(y_test_1)

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):

    plt.figure(figsize = (6,6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=90)
    plt.yticks(tick_marks, classes)
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    thresh = cm.max() / 2.
    cm = np.round(cm,2)
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

train_img = X_train.reshape((X_train.shape[0], 48*48*3))
test_img = X_test.reshape((X_test.shape[0], 48*48*3))
S = StandardScaler()
train_img = S.fit_transform(train_img)
test_img = S.transform(test_img)

# By default, MLP classifier has a single hidden layer with 100 neurons
# and relu activation function
clf = MLPClassifier()
clf.fit(train_img, y_train)
print('Training accuracy:', clf.score(train_img, y_train))
print('Testing accuracy:', clf.score(test_img, y_test))

# Create a confusion matrix
y_pred_encoded = clf.predict(test_img)
mlp_confusion_mtx = confusion_matrix(y_test, y_pred_encoded)
cm = plot_confusion_matrix(mlp_confusion_mtx, classes = tumors, normalize=False)

effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(48,48,3))

model_1 = effnet.output
model_1 = tf.keras.layers.GlobalAveragePooling2D()(model_1)
model_1 = tf.keras.layers.Dropout(rate=0.5)(model_1)
model_1 = tf.keras.layers.Dense(4,activation='softmax')(model_1)
model_1 = tf.keras.models.Model(inputs=effnet.input, outputs = model_1)

model_1.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])

reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001, mode='auto',verbose=1)

history = model_1.fit(X_train,y_train_1,validation_split=0.1, epochs =12, verbose=1, batch_size=32, callbacks=[reduce_lr])

y_pred_encoded = model_1.predict(X_test)
y_pred = np.argmax(y_pred_encoded,axis=1)
print('Training accuracy: ', history.history['accuracy'])
print('Testing accuracy: ', accuracy_score(y_pred, np.argmax(y_test_1, axis=1)))

effnet_confusion_mtx = confusion_matrix(np.argmax(y_test_1, axis=1), y_pred)
cm = plot_confusion_matrix(effnet_confusion_mtx, classes = tumors, normalize=False)

epochs = [i for i in range(12)]
fig, ax = plt.subplots(1,2,figsize=(12,8))
train_acc = history.history['accuracy']
train_loss = history.history['loss']
val_acc = history.history['val_accuracy']
val_loss = history.history['val_loss']

ax[0].plot(epochs, train_acc, marker='o', label = 'Training Accuracy')
ax[0].plot(epochs, val_acc, marker='o', label = 'Validation Accuracy')
ax[0].legend(frameon=False)
ax[0].set_xlabel('Epochs')
ax[0].set_ylabel('Accuracy')
ax[0].set_title('Training vs Validation accuracy')

ax[1].plot(epochs, train_loss, marker='o', label ='Training Loss')
ax[1].plot(epochs, val_loss, marker='o', label = 'Validation Loss')
ax[1].legend(frameon=False)
ax[1].set_xlabel('Epochs')
ax[1].set_ylabel('Loss')
ax[1].set_title('Training vs Validation loss')

fig.show()

# Create the CNN model
model_2 = tf.keras.Sequential()
model_2.add(tf.keras.layers.Conv2D(32, (3, 3), activation="relu", input_shape=(48, 48, 3)))
model_2.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model_2.add(tf.keras.layers.Conv2D(64, (3, 3), activation="relu"))
model_2.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model_2.add(tf.keras.layers.Conv2D(128, (3, 3), activation="relu"))
model_2.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model_2.add(tf.keras.layers.Flatten())
model_2.add(tf.keras.layers.Dense(128, activation="relu"))
model_2.add(tf.keras.layers.Dropout(0.5))
model_2.add(tf.keras.layers.Dense(4, activation="softmax"))

# Compile the model
model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # Adjust the learning rate
              loss="categorical_crossentropy",
              metrics=["accuracy"])

# Train the model
history_2 = model_2.fit(X_train,y_train_1,validation_split=0.1, epochs =12, verbose=1, batch_size=32, callbacks=[reduce_lr])

# Predictions and evaluation
y_pred_encoded = model_2.predict(X_test)
y_pred = np.argmax(y_pred_encoded,axis=1)
print('Training accuracy: ', history_2.history['accuracy'])
print('Testing accuracy: ', accuracy_score(y_pred, np.argmax(y_test_1, axis=1)))

cnn_confusion_mtx = confusion_matrix(np.argmax(y_test_1, axis=1), y_pred)
cm = plot_confusion_matrix(cnn_confusion_mtx, classes = tumors, normalize=False)

epochs = [i for i in range(12)]
fig, ax = plt.subplots(1,2,figsize=(12,8))
train_acc = history_2.history['accuracy']
train_loss = history_2.history['loss']
val_acc = history_2.history['val_accuracy']
val_loss = history_2.history['val_loss']

ax[0].plot(epochs, train_acc, marker='o', label = 'Training Accuracy')
ax[0].plot(epochs, val_acc, marker='o', label = 'Validation Accuracy')
ax[0].legend(frameon=False)
ax[0].set_xlabel('Epochs')
ax[0].set_ylabel('Accuracy')
ax[0].set_title('Training vs Validation accuracy')

ax[1].plot(epochs, train_loss, marker='o', label ='Training Loss')
ax[1].plot(epochs, val_loss, marker='o', label = 'Validation Loss')
ax[1].legend(frameon=False)
ax[1].set_xlabel('Epochs')
ax[1].set_ylabel('Loss')
ax[1].set_title('Training vs Validation loss')

fig.show()

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# jupyter nbconvert --to html /content/Brain_Tumor_2382005.ipynb